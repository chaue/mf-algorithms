{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-negative matrix factorization (NMF) is a simple yet effective method to decompose a matrix into a product of two non-negative matrices(that is sparse matrices with all non-negative entries). This technique is most commonly used in recommender systems, and was made well known by the Netflix Prize. NMF aims to factor a data matrix $X$ into a product of two matrices:\n",
    "\n",
    "$$X \\approx AS $$\n",
    "\n",
    "where $X$ is a $n \\times m$ matrix, $A$ is a $n \\times k$ matrix, and $S$ is a $k \\times m$ matrix. $k$ is usually provided by the user, and symbolizes the number of distinct \"factors\" in the data. For example, if our data was the total productivity of a group of factories per hour for the past week, the number of factors $k$ would be the number of factories. Without prior knowledge the number of factors would be harder to pinpoint, and would have to be chosen using cross validation or something similar\n",
    "\n",
    "It's important to note that this problem does not have a unique solution, and we could end up with many different combinations of $A$ and $S$ that multiply to get a decent approximation of $X$. Even more, each pair of $A$ and $S$ can be scaled by any real number $\\alpha$ and $\\frac{1}{\\alpha}$ respectively to yield an infinite number of pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural question to ask now is how to determine $A$ and $S$ when given $X$ and $k$. One relatively simple method is to use alternating least squares, which is a generalization of the least squares method for simple linear regression. In simple linear regression, the goal is to solve the following equation for $x$:\n",
    "\n",
    "$$ Ax = b \\implies A^TAx = A^Tb \\implies x = (A)^{\\dagger}b\\$$\n",
    "\n",
    "This can be generalized for a product of matrices by picking a random $i^{th}$ column of $X$ and $S$, which we will denote $x_{:,i}$ and $s_{:,i}$, fixing $A$, and solving for $s_{:,i}$. Then by our previous equation $X \\approx AS$ we have \n",
    "\n",
    "$$ x_{:,i} \\approx As_{:,i}$$\n",
    "This yields the following update rule:\n",
    "\n",
    "$$ s_{:,i} := (A)^{\\dagger}x_{:,i}$$\n",
    "\n",
    "However, since we also want to solve for $A$ we need to sample a column of $A$ and fix $S$. To get the same linear form we do the following:\n",
    "\n",
    "$$x_{i,:} \\approx a_{i,:}S \\implies x_{i,:}^T \\approx S^Ta_{i,:}^T$$\n",
    "\n",
    "We switch to updating the rows of $A$ rather than the columns due to dimensionality, and get the following update rule:\n",
    "\n",
    "$$ a_{i,:}^T = (SS^T)^{-1}Sx_{i,:}^T $$\n",
    "\n",
    "We then repeat these updates until convergence or the number of iterations is fulfilled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   5.   0.   0.   5.   0.   0.   0.   5.   0. ]\n",
      " [ 9.  14.   0.   0.  14.   9.   9.   9.  14.   0. ]\n",
      " [ 5.  11.   0.   0.  11.   5.   5.   5.  11.   0. ]\n",
      " [ 3.   9.   0.   0.   9.   3.   3.   3.   9.   0. ]\n",
      " [ 2.  12.   0.   3.  12.   2.   2.   5.   9.   0. ]\n",
      " [ 1.   7.   0.   2.   7.   1.   1.   3.   5.   0. ]\n",
      " [ 0.   3.   0.   1.   3.   0.   0.   1.   2.   0. ]\n",
      " [ 0.   2.   0.   1.   2.   0.   0.   1.   1.   0. ]\n",
      " [ 0.   0.5  0.   0.   0.5  0.   0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "col1 = np.array([[0, 0, 9, 5, 3, 2, 1, 0, 0, 0, 0, 0]])\n",
    "col2 = np.array([[0, 0, 0, 0, 0, 3, 2, 1, 1, 0, 0, 0]])\n",
    "col3 = np.array([[0, 5, 5, 6, 6, 7, 4, 2, 1, 0.5, 0, 0]])\n",
    "\n",
    "factors = np.vstack((col1, col2, col3)).T\n",
    "weights = np.random.randint(0, 2, size=(3, 10))\n",
    "\n",
    "X = np.matmul(factors, weights)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the factor matrices $A$ and $S$ is typically done by filling a matrix of the right dimensions with randomized entries. However, to check that the ALS algorithm works properly we can initialize $A$ and $S$ close to our original factor matrices. The final $A$ and $S$ should yield a very low error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   5.   0.   0.   5.   0.   0.   0.   5.   0. ]\n",
      " [ 9.  14.   0.   0.  14.   9.   9.   9.  14.   0. ]\n",
      " [ 5.  11.   0.   0.  11.   5.   5.   5.  11.   0. ]\n",
      " [ 3.   9.   0.   0.   9.   3.   3.   3.   9.   0. ]\n",
      " [ 2.  12.   0.   3.  12.   2.   2.   5.   9.   0. ]\n",
      " [ 1.   7.   0.   2.   7.   1.   1.   3.   5.   0. ]\n",
      " [ 0.   3.   0.   1.   3.   0.   0.   1.   2.   0. ]\n",
      " [ 0.   2.   0.   1.   2.   0.   0.   1.   1.   0. ]\n",
      " [ 0.   0.5  0.   0.   0.5  0.   0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [-0.   5.   0.   0.   5.   0.  -0.   0.   5.   0. ]\n",
      " [ 9.  14.   0.   0.  14.   9.   9.   9.  14.   0. ]\n",
      " [ 5.  11.   0.  -0.  11.   5.   5.   5.  11.   0. ]\n",
      " [ 3.   9.   0.   0.   9.   3.   3.   3.   9.   0. ]\n",
      " [ 2.  12.   0.   3.  12.   2.   2.   5.   9.   0. ]\n",
      " [ 1.   7.   0.   2.   7.   1.   1.   3.   5.   0. ]\n",
      " [-0.   3.   0.   1.   3.  -0.  -0.   1.   2.   0. ]\n",
      " [-0.   2.   0.   1.   2.  -0.   0.   1.   1.   0. ]\n",
      " [-0.   0.5  0.   0.   0.5  0.  -0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "Relative error:  2.5770494327987753e-16\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "k = 3\n",
    "niter = 1000\n",
    "A = factors + 0.01*np.random.rand(12, 3)\n",
    "S = weights + 0.01*np.random.rand(3, 10)\n",
    "\n",
    "for i in np.arange(niter):\n",
    "    row = np.random.randint(X.shape[0])\n",
    "    col = np.random.randint(X.shape[1])\n",
    "    rowcol = np.random.randint(k)\n",
    "    S[:, col] = np.matmul(np.linalg.pinv(A), X[:, col])\n",
    "    A[row, :] = np.matmul(X[row, :], np.matmul(S.T, np.linalg.inv(np.matmul(S, S.T))))\n",
    "\n",
    "approx = np.matmul(A, S)\n",
    "print(X)\n",
    "print(np.round(approx, 2))\n",
    "print(\"Relative error: \", np.linalg.norm(X - approx) / np.linalg.norm(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the entries of our approximation $AS$ are pretty close to our data matrix, and the relative error is fairly low. Now that the algorithm works we can finalize it in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmfals(data, k, niter, reinit = 5):\n",
    "    # set to negative one so we can guarantee an update for the first init\n",
    "    finalerror = -1\n",
    "    \n",
    "    # need to compare final error to overall best and store the overall best\n",
    "    seqerror = np.empty(niter)\n",
    "    lowesterror = np.empty(1)\n",
    "    \n",
    "    # store overall best factor matrices\n",
    "    lbest = np.random.rand(data.shape[0], k)\n",
    "    rbest = np.random.rand(k, data.shape[1])\n",
    "    \n",
    "    for j in np.arange(reinit):\n",
    "        # randomly initialize the factor matrices\n",
    "        lfactor = np.random.rand(data.shape[0], k)\n",
    "        rfactor = np.random.rand(k, data.shape[1])\n",
    "\n",
    "        for i in np.arange(niter):\n",
    "            # sample random row or column\n",
    "            row = np.random.randint(data.shape[0])\n",
    "            col = np.random.randint(data.shape[1])\n",
    "            # perform linear reg update \n",
    "            rfactor[:, col] = np.matmul(np.linalg.pinv(lfactor), data[:, col])\n",
    "            lfactor[row, :] = np.matmul(data[row, :], np.matmul(rfactor.T, np.linalg.inv(np.matmul(rfactor, rfactor.T))))\n",
    "            # calculate error after update\n",
    "            seqerror[i] = np.linalg.norm(data - np.matmul(lfactor, rfactor)) / np.linalg.norm(data)\n",
    "        # update after first init\n",
    "        if (finalerror == -1):\n",
    "            lowesterror = seqerror\n",
    "            lbest = lfactor\n",
    "            rbest = rfactor\n",
    "        # if not first, only update if final error is lower than overall best\n",
    "        elif (finalerror > seqerror[niter - 1]):\n",
    "            finalerror = seqerror[niter - 1]\n",
    "            lowesterror = seqerror\n",
    "            lbest = lfactor\n",
    "            rbest = rfactor\n",
    "    return(lbest, rbest, lowesterror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.02  4.96  0.    0.03  5.   -0.02  0.   -0.02  5.    0.  ]\n",
      " [ 9.02 13.98  0.    0.03 14.    8.99  9.    8.99 14.02  0.  ]\n",
      " [ 5.02 10.97  0.    0.04 11.01  4.98  5.    4.98 11.02  0.  ]\n",
      " [ 3.02  8.96  0.    0.04  9.    2.98  3.    2.98  9.    0.  ]\n",
      " [ 2.01 12.11  0.    3.   11.98  2.    2.    4.98  8.96  0.  ]\n",
      " [ 0.99  7.12  0.    2.    7.03  1.    0.99  2.99  5.01  0.  ]\n",
      " [-0.    3.06  0.    1.    3.02 -0.   -0.    1.    2.    0.  ]\n",
      " [-0.    2.03  0.    0.99  1.98  0.01  0.    1.    0.98  0.  ]\n",
      " [ 0.    0.5   0.    0.    0.5  -0.   -0.   -0.    0.5   0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
      "0.004703813267021602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#np.random.seed(1)\n",
    "A, S, error = nmfals(X, 3, 100, 10)\n",
    "print(np.round(np.matmul(A,S), 2))\n",
    "print(error[99])\n",
    "plt.plot(error)\n",
    "plt.title(\"Relative error vs Iteration\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the ALS algorithm does not always closely resemble the original data matrix in practice, as the random initializations of $A$ and $S$ can cause the resulting approximation to vary wildly even with multiple iterations. This makes sense, as there are many different factorizations that a matrix can have. While the factorized $A$ and $S$ don't form a matrix that matches $X$ closely, it did preserve the row and column of zeros that were present in $X$. \n",
    "\n",
    "One thing to note is we use the relative error to judge the quality of our approximation, which is the Frobenius norm of the difference between our original data matrix $X$ and the approximation $AS$ divided by the Frobenius norm of $X$. We do this rather than just use the raw error since factorizations can be scaled by multiplying $A$ by a number $r$ and $S$ by $\\frac{1}{r}$. This scaling also scales the error, hence the need for a relative metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Kaczmarz Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw previously that the algorithm to factorize $X$ has two main parts, one to pick our matrix column and row indices and one to take an iterative step towards the local optimum. The iterative step gives us the freedom to choose our favorite method to solve for $A$ and $S$, and rather than doing a traditional least squares method we can try applying the Randomized Kaczmarz(RK) method instead. This iterative step takes our randomly chosen row/column of either $A$ or $S$ and projects it towards the local optimum. It is equivalent to stochastic gradient descent with a specific step size when the matrix is positive definite.\n",
    "\n",
    "Our current system $AS = X$ is reduced to $As_{:,i} = x_{:,i}$ when a column is sampled. Our RK iterative step then samples a row of $A$ and corresponding entry $k$ of $s_{:,i}$ and would then be the following:\n",
    "\n",
    "$$s_{:,i}^{(j+1)} = s_{:,i}^{(j)} + \\frac{x_{k,i} - a_{k,:}^Ts_{:,i}}{\\lvert\\lvert{a_{k,:}}\\rvert\\rvert ^2}a_{k,:}$$\n",
    "\n",
    "Note that $j$ represents the current iteration of our RK method. This value can be explicitly chosen, making it an additional parameter in this algorithm. If we sampled a row of $S$ rather than a column of $A$, each step would instead be the following:\n",
    "\n",
    "$$a_{i,:}^{(j+1)} = a_{i,:}^{(j)} + \\frac{x_{i,k} - a_{i,:}^Ts_{:,k}}{\\lvert\\lvert{s_{:,k}}\\rvert\\rvert ^2}s_{:,k}$$\n",
    "\n",
    "To summarize, we start by randomly sampling a row/column to reduce to a linear system(as usual). We then proceed to take RK steps, with each step sampling a random row and entry and updating. The number of steps before resampling our linear system can be provided as a parameter. \n",
    "\n",
    "We can also perform quick sanity check by initializing $A$ and $S$ close to the original factor matrices like we did with the ALS method. It's important to note that dividing by a vector norm means that we have to avoid sampling the rows/columns of our factor matrices that are all zero. This can be done by doing a weighted sample based on the norms of the rows/columns where a row with twice the magnitude of another will be sampled twice as often and a row with zero norm will never be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightsample(data, mode):\n",
    "    prob = np.linalg.norm(data, axis=mode)\n",
    "    return(prob / sum(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   5.   0.   0.   5.   0.   0.   0.   5.   0. ]\n",
      " [ 9.  14.   0.   0.  14.   9.   9.   9.  14.   0. ]\n",
      " [ 5.  11.   0.   0.  11.   5.   5.   5.  11.   0. ]\n",
      " [ 3.   9.   0.   0.   9.   3.   3.   3.   9.   0. ]\n",
      " [ 2.  12.   0.   3.  12.   2.   2.   5.   9.   0. ]\n",
      " [ 1.   7.   0.   2.   7.   1.   1.   3.   5.   0. ]\n",
      " [ 0.   3.   0.   1.   3.   0.   0.   1.   2.   0. ]\n",
      " [ 0.   2.   0.   1.   2.   0.   0.   1.   1.   0. ]\n",
      " [ 0.   0.5  0.   0.   0.5  0.   0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "[[-0.   -0.    0.   -0.   -0.02 -0.    0.   -0.   -0.    0.  ]\n",
      " [ 0.89  0.29 -0.01 -0.06  5.12 -0.36 -0.51  0.55 -0.32 -0.01]\n",
      " [ 9.    8.67 -0.03 -0.   26.76  7.24  2.8   8.96  6.89 -0.  ]\n",
      " [ 7.87  8.94 -0.01  0.08 16.69  9.47  4.73  8.79  8.32  0.02]\n",
      " [ 4.61  4.85 -0.01  0.24 13.98  2.94  0.94  4.44  4.65 -0.  ]\n",
      " [ 5.48  6.98  0.01  0.93 16.69  1.83  0.05  5.    8.65  0.01]\n",
      " [ 3.65  3.78 -0.    0.42 13.85  0.34 -0.64  3.    4.03 -0.01]\n",
      " [ 2.01  2.75  0.01  0.41  5.85  0.62  0.    1.84  3.6   0.  ]\n",
      " [ 0.09  2.    0.03  0.86 -1.24 -1.41 -0.85 -0.07  4.74  0.02]\n",
      " [ 0.08  0.32  0.    0.08 -0.21  0.09  0.06  0.12  0.59  0.  ]\n",
      " [-0.    0.    0.    0.   -0.01  0.    0.   -0.    0.01  0.  ]\n",
      " [-0.   -0.    0.    0.   -0.02  0.    0.   -0.    0.    0.  ]]\n",
      "0.5396653015850852\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "k = 3\n",
    "niter = 100\n",
    "factors = factors \n",
    "weights = weights \n",
    "X = np.round(np.matmul(factors, weights), 2)\n",
    "\n",
    "A = factors + 0.01*np.random.rand(12, 3)\n",
    "S = weights + 0.01*np.random.rand(3, 10)\n",
    "\n",
    "kacziters = 1000\n",
    "for j in np.arange(niter):\n",
    "    row = np.random.choice(X.shape[0], p = weightsample(X, 1))\n",
    "    col = np.random.choice(X.shape[1], p = weightsample(X, 0))\n",
    "    for i in np.arange(kacziters):\n",
    "        kaczrow = np.random.randint(len(X[:, col]))\n",
    "        kaczcol = np.random.randint(len(X[row, :]))\n",
    "        S[:, col] = S[:, col] + (X[kaczrow, col] - np.matmul(A[kaczrow, :], S[:, col])) / (np.linalg.norm(A[kaczrow, :])**2) * A[kaczrow, :]\n",
    "        A[row, :] = A[row, :] + (X[row, kaczcol] - np.matmul(A[row, :], S[:, kaczcol])) / (np.linalg.norm(S[:, kaczcol])**2) * S[:, kaczcol] \n",
    "\n",
    "approx = np.matmul(A, S)\n",
    "print(X)\n",
    "print(np.round(approx, 2))\n",
    "print(np.linalg.norm(X - approx) / np.linalg.norm(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RK method's relative error is nowhere near comparable to that of ALS even when the number of RK iterations is in the thousands due to the presence of more negative entries. \n",
    "\n",
    "The finalized function is largely similar to the ALS one, except the ALS iterative step is substituted for the RK iteration loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmfrk(data, k, niter, kacziter, reinit = 5):\n",
    "    # set to negative one so we can guarantee an update for the first init\n",
    "    finalerror = -1\n",
    "    \n",
    "    # need to compare final error to overall best and store the overall best\n",
    "    seqerror = np.empty(niter)\n",
    "    lowesterror = np.empty(1)\n",
    "    \n",
    "    # store overall best factor matrices\n",
    "    lbest = np.random.rand(data.shape[0], k)\n",
    "    rbest = np.random.rand(k, data.shape[1])\n",
    "    \n",
    "    for l in np.arange(reinit):\n",
    "        # randomly initialize the factor matrices\n",
    "        lfactor = np.random.rand(data.shape[0], k)\n",
    "        rfactor = np.random.rand(k, data.shape[1])\n",
    "        \n",
    "        # outer loop for number of iterations \n",
    "        for i in np.arange(niter):\n",
    "            \n",
    "            # weighted sampling of row and column from data matrix\n",
    "            row = np.random.choice(data.shape[0], p = weightsample(data, 1))\n",
    "            col = np.random.choice(data.shape[1], p = weightsample(data, 0))\n",
    "            \n",
    "            # inner loop for number of RK iterations\n",
    "            for j in np.arange(kacziter):\n",
    "                # sample index for entry of data matrix\n",
    "                kaczrow = np.random.choice(data.shape[0], p = weightsample(data, 1))\n",
    "                kaczcol = np.random.choice(data.shape[1], p = weightsample(data, 0))\n",
    "                # compute RK step\n",
    "                #print(np.linalg.norm(rfactor[:, kaczcol])**2)\n",
    "                #print(np.linalg.norm(lfactor[kaczrow, :])**2)\n",
    "                lfactor[row, :] = lfactor[row, :] + (data[row, kaczcol] - np.matmul(lfactor[row, :], rfactor[:, kaczcol])) / (np.linalg.norm(rfactor[:, kaczcol])**2) * rfactor[:, kaczcol] \n",
    "                rfactor[:, col] = rfactor[:, col] + (data[kaczrow, col] - np.matmul(lfactor[kaczrow, :], rfactor[:, col])) / (np.linalg.norm(lfactor[kaczrow, :])**2) * lfactor[kaczrow, :]\n",
    "            # calculate error after update\n",
    "            seqerror[i] = np.linalg.norm(data - np.matmul(lfactor, rfactor)) / np.linalg.norm(data)\n",
    "        # update after first init\n",
    "        if (finalerror == -1):\n",
    "            lowesterror = seqerror\n",
    "            lbest = lfactor\n",
    "            rbest = rfactor\n",
    "        # if not first, only update if final error is lower than overall best\n",
    "        elif (finalerror > seqerror[niter - 1]):\n",
    "            finalerror = seqerror[niter - 1]\n",
    "            lowesterror = seqerror\n",
    "            lbest = lfactor\n",
    "            rbest = rfactor\n",
    "    return(lbest, rbest, lowesterror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21577893  0.1116762   0.34280376]\n",
      " [ 0.3560583   0.13566787 -0.15387167]\n",
      " [ 7.32805132  0.32329357 14.44250909]\n",
      " [ 6.74859594  0.62648174 14.05800652]\n",
      " [ 3.40611811 -0.71300333  7.67699462]\n",
      " [ 2.34971915  2.99210388  5.18087682]\n",
      " [ 0.64917989  2.82237752  2.59965052]\n",
      " [-0.13435204  0.78207134  0.72952182]\n",
      " [ 0.77398651 -0.51491179  1.32318337]\n",
      " [ 0.21971258  0.97096085  0.75409981]\n",
      " [ 0.76941528  0.61508838  0.79236535]\n",
      " [ 0.33796544  0.35103269  0.90140973]]\n",
      "[[ 0.17993968 10.10502961  0.03057856 -0.33168941  9.48338529  0.16948831\n",
      "   0.25715601  0.05199888 10.8861903   0.93054263]\n",
      " [ 0.05274966  5.16250883  0.4260751   1.00054531  3.34957628 -0.01152112\n",
      "  -0.21127135  0.50332145  3.16155816  0.90992732]\n",
      " [ 0.25846509 -4.55986322  0.46250114  0.11467857 -3.91933122  0.35485099\n",
      "   0.391437    0.54599198 -4.62500471  0.36657941]]\n",
      "0.7247767247999287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iteration')"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A, S, error = nmfrk(X, k = 3, niter = 100, kacziter = 1000, reinit = 5)\n",
    "\n",
    "approx = np.matmul(A, S)\n",
    "#print(X)\n",
    "print(A)\n",
    "print(S)\n",
    "#print(np.round(approx, 2))\n",
    "print(np.linalg.norm(X - approx) / np.linalg.norm(X))\n",
    "plt.plot(error)\n",
    "plt.title(\"Relative error vs Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start to notice that RK is more inclined to have negative entries, which further increases the error as other entries grow larger to compensate. We can address this problem by introducing a nonnegativity constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Projection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest and easiest method is to project each iteration into the feasible space, which in this case is the nonnegative numbers. We merely need to check whether an element of our iteration result is negative, and set it directly to 0 if so. That is,\n",
    "\n",
    "$$ x_{k,i} = \\max{ \\{ x_{k,i}, 0 \\}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(vec, i):\n",
    "    return(np.where(vec < 0, 0, vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmfrk2(data, f, k, niter, kacziter, reinit = 5):\n",
    "    # set to negative one so we can guarantee an update for the first init\n",
    "    finalerror = -1\n",
    "    \n",
    "    # need to compare final error to overall best and store the overall best\n",
    "    seqerror = np.empty(niter)\n",
    "    lowesterror = np.empty(1)\n",
    "    \n",
    "    # store overall best factor matrices\n",
    "    lbest = np.random.rand(data.shape[0], k)\n",
    "    rbest = np.random.rand(k, data.shape[1])\n",
    "    \n",
    "    for l in np.arange(reinit):\n",
    "        # randomly initialize the factor matrices\n",
    "        lfactor = np.random.rand(data.shape[0], k)\n",
    "        rfactor = np.random.rand(k, data.shape[1])\n",
    "        \n",
    "        # outer loop for number of iterations \n",
    "        for i in np.arange(niter):\n",
    "            \n",
    "            # weighted sampling of row and column from data matrix\n",
    "            row = np.random.choice(data.shape[0], p = weightsample(data, 1))\n",
    "            col = np.random.choice(data.shape[1], p = weightsample(data, 0))\n",
    "            \n",
    "            # inner loop for number of RK iterations\n",
    "            for j in np.arange(kacziter):\n",
    "                # sample index for entry of data matrix\n",
    "                kaczrow = np.random.choice(data.shape[0], p = weightsample(data, 1))\n",
    "                kaczcol = np.random.choice(data.shape[1], p = weightsample(data, 0))\n",
    "                # compute RK step\n",
    "                #print(j)\n",
    "                lfactor[row, :] = lfactor[row, :] + (data[row, kaczcol] - np.matmul(lfactor[row, :], rfactor[:, kaczcol])) / (np.linalg.norm(rfactor[:, kaczcol])**2) * rfactor[:, kaczcol] \n",
    "                rfactor[:, col] = rfactor[:, col] + (data[kaczrow, col] - np.matmul(lfactor[kaczrow, :], rfactor[:, col])) / (np.linalg.norm(lfactor[kaczrow, :])**2) * lfactor[kaczrow, :]\n",
    "                #print(lfactor[row, :])\n",
    "                #print(rfactor[:, col])\n",
    "                \n",
    "                # project to feasible space\n",
    "                lfactor[row, :] = f(lfactor[row, :], j+1)\n",
    "                rfactor[:, col] = f(rfactor[:, col], j+1)\n",
    "                #print(lfactor[row, :])\n",
    "                #print(rfactor[:, col])\n",
    "                \n",
    "            # calculate error after update\n",
    "            seqerror[i] = np.linalg.norm(data - np.matmul(lfactor, rfactor)) / np.linalg.norm(data)\n",
    "        # update after first init\n",
    "        if (finalerror == -1):\n",
    "            lowesterror = seqerror\n",
    "            lbest = lfactor\n",
    "            rbest = rfactor\n",
    "        # if not first, only update if final error is lower than overall best\n",
    "        elif (finalerror > seqerror[niter - 1]):\n",
    "            finalerror = seqerror[niter - 1]\n",
    "            lowesterror = seqerror\n",
    "            lbest = lfactor\n",
    "            rbest = rfactor\n",
    "    return(lbest, rbest, lowesterror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Edwin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in less\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   5.   0.   0.   5.   0.   0.   0.   5.   0. ]\n",
      " [ 9.  14.   0.   0.  14.   9.   9.   9.  14.   0. ]\n",
      " [ 5.  11.   0.   0.  11.   5.   5.   5.  11.   0. ]\n",
      " [ 3.   9.   0.   0.   9.   3.   3.   3.   9.   0. ]\n",
      " [ 2.  12.   0.   3.  12.   2.   2.   5.   9.   0. ]\n",
      " [ 1.   7.   0.   2.   7.   1.   1.   3.   5.   0. ]\n",
      " [ 0.   3.   0.   1.   3.   0.   0.   1.   2.   0. ]\n",
      " [ 0.   2.   0.   1.   2.   0.   0.   1.   1.   0. ]\n",
      " [ 0.   0.5  0.   0.   0.5  0.   0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "[[ 0.5  1.8  0.3  0.2  1.8  0.5  0.5  0.7  1.3  0.7]\n",
      " [ 0.1  6.8  1.5  2.1  8.9  0.1  0.   1.6  4.4  2.6]\n",
      " [ 9.  21.5  3.   0.2 16.6  8.4  8.4 10.7 16.6  8. ]\n",
      " [ 5.1 13.3  2.   0.4 11.   4.7  4.7  6.2 10.1  5. ]\n",
      " [ 3.1  9.2  1.4  0.5  8.1  2.9  2.9  4.   6.9  3.5]\n",
      " [ 2.1 12.   2.2  3.  12.8  1.9  1.9  4.5  8.3  4.3]\n",
      " [ 1.1  7.7  1.4  3.1  7.9  1.   0.9  3.4  5.1  2.5]\n",
      " [ 0.   2.4  0.5  1.1  3.   0.   0.   0.8  1.5  0.8]\n",
      " [ 0.1  3.3  0.7  1.5  4.   0.1  0.1  1.2  2.1  1.1]\n",
      " [ 0.   0.5  0.1  0.1  0.7  0.   0.   0.1  0.3  0.2]\n",
      " [ 0.2  2.2  0.4  0.7  2.5  0.2  0.2  0.7  1.5  0.8]\n",
      " [ 0.1  3.6  0.7  1.6  4.3  0.1  0.   1.2  2.2  1.2]]\n",
      "0.39096265301291055\n"
     ]
    }
   ],
   "source": [
    "A, S, error = nmfrk2(X, proj, k = 3, niter = 50, kacziter = 1000, reinit = 5)\n",
    "\n",
    "approx = np.matmul(A, S)\n",
    "print(X)\n",
    "print(np.round(approx, 1))\n",
    "print(np.linalg.norm(X - approx) / np.linalg.norm(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we got a matrix full of NaNs, which means our iterative step size was most likely divided by zero during the algorithm run time. We had the same issue when uniformly sampling a data matrix that contained rows and columns of zeros, which means our projection method encountered a row or column of negative numbers and set the whole row or column to zero. Because we don't perform a weighted sample of the kaczmarz indices, this resulted in an error when attempting to divide by zero. Rather than a direct projection to zero, we can try instead to perform a \"soft\" projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: \"Soft\" Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because a direct projection failed to work, we can try a \"soft\" projection where negative entries are sent to a negative value very close to zero. This way a full row or column of negative entries won't cause any computational errors. This can either be done by assigning to a constant or a value dependent on iteration count. That is\n",
    "\n",
    "$$ x_{k,i} = \\max{ \\{ x_{k,i}, -c \\}} \\text{,  } c << 10^{-3} \\textbf{  or} $$\n",
    "$$ x_{k,i} = \\max{ \\{ x_{k,i}, -\\frac{1}{\\sqrt{j}} \\}},  j^{th} \\text{ iteration}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softprojc(vec, i, c = -1e-5):\n",
    "    return(np.where(vec < c, c, vec))\n",
    "def softproji(vec, i):\n",
    "    return(np.where(vec < 0, (-1 / np.sqrt(i)), vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66379465  0.51488911  0.94459476]\n",
      " [-0.00001     0.2382541  -0.00001   ]\n",
      " [ 4.20307538  1.68335524 -0.00001   ]\n",
      " [ 2.4634237   2.76714622  0.82926235]\n",
      " [ 1.47609624  1.22003238  0.18601832]\n",
      " [ 0.78468864  1.63591619  1.29690273]\n",
      " [ 0.39246717  0.62654492  1.26516088]\n",
      " [-0.00001     0.61621383  0.59444764]\n",
      " [ 0.00434291  0.1434014   0.65839425]\n",
      " [ 0.57838961  0.4081368   0.23702698]\n",
      " [ 0.90337952  0.57367949  0.00287033]\n",
      " [ 0.61714491  0.3266449   0.5270581 ]]\n",
      "[[ 1.76860446  0.02723516  0.90853515  0.09933065 -0.00001     2.12052261\n",
      "   2.0599196   0.90284063 -0.00001     0.13713575]\n",
      " [ 0.28217887  7.25398884  0.06600017  0.08271308  7.33535181  0.05185174\n",
      "   0.17690263  1.95266772  7.0246585   0.02621099]\n",
      " [ 0.24246129  1.45756064  0.86002795  1.59649392 -0.00001     0.1248185\n",
      "   0.07445238  1.12415005 -0.00001     0.96959575]]\n",
      "0.5102437822175373\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A, S, error = nmfrk2(X, softprojc, k = 3, niter = 100, kacziter = 1000, reinit = 1)\n",
    "\n",
    "approx = np.matmul(A, S)\n",
    "#print(X)\n",
    "print(A)\n",
    "print(S)\n",
    "#print(np.round(approx, 1))\n",
    "print(np.linalg.norm(X - approx) / np.linalg.norm(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   5.   0.   0.   5.   0.   0.   0.   5.   0. ]\n",
      " [ 9.  14.   0.   0.  14.   9.   9.   9.  14.   0. ]\n",
      " [ 5.  11.   0.   0.  11.   5.   5.   5.  11.   0. ]\n",
      " [ 3.   9.   0.   0.   9.   3.   3.   3.   9.   0. ]\n",
      " [ 2.  12.   0.   3.  12.   2.   2.   5.   9.   0. ]\n",
      " [ 1.   7.   0.   2.   7.   1.   1.   3.   5.   0. ]\n",
      " [ 0.   3.   0.   1.   3.   0.   0.   1.   2.   0. ]\n",
      " [ 0.   2.   0.   1.   2.   0.   0.   1.   1.   0. ]\n",
      " [ 0.   0.5  0.   0.   0.5  0.   0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "[[ 1.1  6.3  1.4  1.   3.7  1.3  1.2  2.3  3.2  1. ]\n",
      " [-0.   4.9  1.   0.8  2.1  0.3  0.1 -0.2  1.8  1.1]\n",
      " [ 8.6  7.5  5.3  0.7 10.2  9.   8.3  8.4 12.   0.8]\n",
      " [ 4.2 17.5  5.3  2.5 11.   5.2  4.5  3.8 11.   3.5]\n",
      " [ 3.   9.2  3.1  1.3  6.4  3.5  3.1  2.8  6.6  1.7]\n",
      " [ 2.  23.   4.4  3.7 12.   2.9  2.4  6.9  9.5  3.9]\n",
      " [ 0.8  7.3  1.3  1.2  4.   1.   0.9  3.   3.   1.1]\n",
      " [ 0.2  5.1  0.1  1.   2.8  0.1  0.2  5.5  0.9  0. ]\n",
      " [ 0.   2.   0.2  0.4  0.9  0.   0.   1.   0.5  0.2]\n",
      " [ 0.9  2.9  0.8  0.4  2.   1.   0.9  1.9  1.8  0.3]\n",
      " [ 1.4  2.7  0.9  0.4  2.4  1.4  1.4  2.9  2.2  0.1]\n",
      " [ 1.   4.   1.   0.6  2.6  1.1  1.   1.8  2.3  0.6]]\n",
      "0.5081891210633053\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A, S, error = nmfrk2(X, softproji, k = 3, niter = 100, kacziter = 1000, reinit = 1)\n",
    "\n",
    "approx = np.matmul(A, S)\n",
    "print(X)\n",
    "print(np.round(approx, 1))\n",
    "print(np.linalg.norm(X - approx) / np.linalg.norm(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Line search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more option to ensure nonnegativity is to perform a line search along the orthogonal projection during a typical RK step. This allows us to \"backtrack\" until we're left with all nonnegative entries, which is more natural than a projection of all negative entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error plots\n",
    "fixed als and rk row sampling, led to greatly improved performance of als\n",
    "fixed kacz index sampling so hard projection does not throw an error and soft projection does not blow up entries \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
